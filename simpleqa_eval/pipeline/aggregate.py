"""èšåˆç»Ÿè®¡æ¨¡å—

è¯»å– sample_results.csv â†’ æŒ‰ Jaccard åˆ† 5 æ¡¶ â†’ è¾“å‡º bucket_stats.csv
"""

import logging
import pandas as pd
import numpy as np
from pathlib import Path

logger = logging.getLogger(__name__)


def aggregate_buckets(
    sample_csv: str,
    output_csv: str,
    n_buckets: int = 5,
) -> pd.DataFrame:
    """æŒ‰ Jaccard åˆ†æ¡¶å¹¶ç»Ÿè®¡å„æ¡¶æŒ‡æ ‡ã€‚

    Args:
        sample_csv: æ ·æœ¬çº§ç»“æœ CSV è·¯å¾„
        output_csv: æ¡¶ç»Ÿè®¡è¾“å‡º CSV è·¯å¾„
        n_buckets: æ¡¶æ•°é‡ï¼ˆé»˜è®¤ 5ï¼‰

    Returns:
        æ¡¶ç»Ÿè®¡ DataFrame
    """
    logger.info(f"ğŸ“Š è¯»å–æ ·æœ¬ç»“æœ: {sample_csv}")
    df = pd.read_csv(sample_csv)
    df["jaccard_proxy"] = pd.to_numeric(df["jaccard_proxy"], errors="coerce")

    total = len(df)
    valid = df["jaccard_proxy"].notna().sum()
    dropped = total - valid
    logger.info(f"   æ€»æ ·æœ¬: {total}, æœ‰ Jaccard å€¼: {valid}, ç¼ºå¤±: {dropped}")
    if dropped > 0:
        logger.warning(f"   âš ï¸  {dropped} æ¡æ ·æœ¬æ—  Jaccard å€¼ (NaN)ï¼Œä¸å‚ä¸åˆ†æ¡¶ä½†ä¼šè®°å½•")

    # åªå¯¹æœ‰ Jaccard å€¼çš„æ ·æœ¬åˆ†æ¡¶
    df_valid = df[df["jaccard_proxy"].notna()].copy()

    if len(df_valid) < n_buckets:
        logger.error(f"   âŒ æœ‰æ•ˆæ ·æœ¬({len(df_valid)})å°‘äºæ¡¶æ•°({n_buckets})ï¼Œæ— æ³•åˆ†æ¡¶")
        return pd.DataFrame()

    # åˆ†ä½æ•°åˆ†æ¡¶
    try:
        df_valid["bucket_num"] = pd.qcut(
            df_valid["jaccard_proxy"],
            q=n_buckets,
            labels=False,
            duplicates="drop",
        )
    except ValueError as e:
        logger.warning(f"   âš ï¸  qcut å¤±è´¥: {e}ï¼Œæ”¹ç”¨å‡åŒ€åˆ†æ¡¶")
        df_valid["bucket_num"] = pd.cut(
            df_valid["jaccard_proxy"],
            bins=n_buckets,
            labels=False,
        )

    df_valid = df_valid[df_valid["bucket_num"].notna()].copy()
    if df_valid.empty:
        logger.error("   âŒ åˆ†æ¡¶åæ— æœ‰æ•ˆæ¡¶ï¼ˆå¯èƒ½ Jaccard å€¼å®Œå…¨ç›¸åŒï¼‰ï¼Œæ— æ³•ç»Ÿè®¡")
        return pd.DataFrame()

    # T1 = æœ€é«˜ Jaccard, T5 = æœ€ä½
    actual_buckets = df_valid["bucket_num"].nunique()
    if actual_buckets < n_buckets:
        logger.warning(f"   âš ï¸  å®é™…åªå½¢æˆ {actual_buckets} ä¸ªæ¡¶ï¼ˆç›®æ ‡ {n_buckets}ï¼‰")
    max_bucket = df_valid["bucket_num"].max()
    df_valid["bucket"] = df_valid["bucket_num"].apply(
        lambda x: f"T{int(max_bucket - x) + 1}"
    )

    # æŒ‰æ¡¶ç»Ÿè®¡
    stats = []
    for bucket_name in sorted(df_valid["bucket"].unique()):
        bucket_df = df_valid[df_valid["bucket"] == bucket_name]
        stat = {
            "bucket": bucket_name,
            "n_samples": len(bucket_df),
            "mean_jaccard": bucket_df["jaccard_proxy"].mean(),
            "min_jaccard": bucket_df["jaccard_proxy"].min(),
            "max_jaccard": bucket_df["jaccard_proxy"].max(),
            "hallucination_rate": bucket_df["is_hallucination"].mean(),
        }

        if "self_consistency" in bucket_df.columns:
            stat["mean_self_consistency"] = bucket_df["self_consistency"].mean()

        if "confidence" in bucket_df.columns:
            stat["mean_confidence"] = bucket_df["confidence"].mean()

        if "wiki_failed" in bucket_df.columns:
            stat["wiki_failure_rate"] = bucket_df["wiki_failed"].mean()

        stats.append(stat)

    stats_df = pd.DataFrame(stats)

    # è¾“å‡º
    Path(output_csv).parent.mkdir(parents=True, exist_ok=True)
    stats_df.to_csv(output_csv, index=False)
    logger.info(f"ğŸ’¾ æ¡¶ç»Ÿè®¡å·²ä¿å­˜: {output_csv}")

    # æ‰“å°è¡¨æ ¼
    logger.info("\n" + "=" * 70)
    logger.info("  ğŸ“Š åˆ†æ¡¶ç»Ÿè®¡ç»“æœ")
    logger.info("=" * 70)
    for _, row in stats_df.iterrows():
        line = (
            f"  {row['bucket']}  |  "
            f"n={int(row['n_samples']):>4d}  |  "
            f"Jaccard={row['mean_jaccard']:.4f}  |  "
            f"HalluRate={row['hallucination_rate']:.3f}"
        )
        if "mean_self_consistency" in row and pd.notna(row.get("mean_self_consistency")):
            line += f"  |  SelfConsis={row['mean_self_consistency']:.3f}"
        if "mean_confidence" in row and pd.notna(row.get("mean_confidence")):
            line += f"  |  Confidence={row['mean_confidence']:.4f}"
        if "wiki_failure_rate" in row and pd.notna(row.get("wiki_failure_rate")):
            line += f"  |  WikiFail={row['wiki_failure_rate']:.3f}"
        logger.info(line)
    logger.info("=" * 70)

    # ä¹Ÿä¿å­˜åˆ†æ¡¶åçš„æ ·æœ¬çº§ç»“æœ
    df_valid.to_csv(
        str(Path(output_csv).parent / "sample_results_bucketed.csv"),
        index=False,
    )

    return stats_df
