"""SimpleQA æ•°æ®åŠ è½½å™¨

ä» HuggingFace openai/simple-evals åŠ è½½ SimpleQA æ•°æ®é›†ã€‚
"""

import csv
import json
import logging
from pathlib import Path
from typing import List, Dict, Optional

logger = logging.getLogger(__name__)


def load_simpleqa(first_n: int = -1, cache_path: Optional[str] = None) -> List[Dict]:
    """åŠ è½½ SimpleQA æ•°æ®é›†ã€‚

    ä¼˜å…ˆä»æœ¬åœ°ç¼“å­˜åŠ è½½ï¼Œå¦åˆ™ä» HuggingFace ä¸‹è½½ã€‚

    Args:
        first_n: å–å‰ N æ¡ï¼Œ-1 è¡¨ç¤ºå…¨éƒ¨
        cache_path: æœ¬åœ°ç¼“å­˜æ–‡ä»¶è·¯å¾„

    Returns:
        List[dict]ï¼Œæ¯æ¡åŒ…å« qid, question, ground_truth
    """
    from simpleqa_eval.config import CACHE_DIR

    if cache_path is None:
        cache_path = str(CACHE_DIR / "simpleqa_dataset.json")

    cache_file = Path(cache_path)

    # å°è¯•ä»ç¼“å­˜åŠ è½½
    if cache_file.exists():
        logger.info(f"ğŸ“‚ ä»ç¼“å­˜åŠ è½½ SimpleQA: {cache_file}")
        with open(cache_file, "r", encoding="utf-8") as f:
            data = json.load(f)
        logger.info(f"   ç¼“å­˜ä¸­å…± {len(data)} æ¡æ ·æœ¬")
        if first_n > 0:
            data = data[:first_n]
            logger.info(f"   æˆªå–å‰ {first_n} æ¡")
        return data

    # ä» HuggingFace ä¸‹è½½
    logger.info("ğŸŒ ä» HuggingFace ä¸‹è½½ SimpleQA æ•°æ®é›†...")
    try:
        from datasets import load_dataset
        ds = load_dataset("basicv8vc/SimpleQA", split="test")
    except Exception as e:
        logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
        logger.info("ğŸ’¡ å°è¯•å¤‡ç”¨æ–¹å¼ï¼šç›´æ¥ä¸‹è½½ CSV...")
        return _download_csv_fallback(first_n, cache_file)

    data = []
    for idx, row in enumerate(ds):
        item = {
            "qid": idx,
            "question": row.get("problem", ""),
            "ground_truth": row.get("answer", ""),
        }
        data.append(item)

    logger.info(f"âœ… åŠ è½½å®Œæˆï¼Œå…± {len(data)} æ¡æ ·æœ¬")

    # ä¿å­˜ç¼“å­˜
    cache_file.parent.mkdir(parents=True, exist_ok=True)
    with open(cache_file, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    logger.info(f"ğŸ’¾ å·²ç¼“å­˜åˆ° {cache_file}")

    if first_n > 0:
        data = data[:first_n]
        logger.info(f"   æˆªå–å‰ {first_n} æ¡")

    return data


def _download_csv_fallback(first_n: int, cache_file: Path) -> List[Dict]:
    """å¤‡ç”¨ä¸‹è½½æ–¹å¼ï¼šç”¨ requests ç›´æ¥ä¸‹è½½ CSV"""
    import requests

    url = "https://openaipublic.blob.core.windows.net/simple-evals/simple_qa_test_set.csv"
    logger.info(f"   ä¸‹è½½ URL: {url}")

    resp = requests.get(url, timeout=60)
    resp.raise_for_status()

    lines = resp.text.strip().split("\n")
    reader = csv.DictReader(lines)

    data = []
    for idx, row in enumerate(reader):
        item = {
            "qid": idx,
            "question": row.get("problem", ""),
            "ground_truth": row.get("answer", ""),
        }
        data.append(item)

    logger.info(f"âœ… CSV ä¸‹è½½å®Œæˆï¼Œå…± {len(data)} æ¡æ ·æœ¬")

    # ä¿å­˜ç¼“å­˜
    cache_file.parent.mkdir(parents=True, exist_ok=True)
    with open(cache_file, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    logger.info(f"ğŸ’¾ å·²ç¼“å­˜åˆ° {cache_file}")

    if first_n > 0:
        data = data[:first_n]

    return data
